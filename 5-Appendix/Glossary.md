# Glossary

*   **AGI (Artificial General Intelligence):** A hypothetical type of AI that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks at a level comparable to human intelligence.
*   **Alignment Problem:** The challenge of ensuring that an AGI's goals and behaviors are aligned with human values and interests.
*   **Constraint Enforcer (CE):** A software component that evaluates proposed actions from the AGI against a set of inviolable constraints before allowing execution.
*   **Corral:** The contained hardware and software environment where the AGI operates, subject to strict constraints and monitoring.
*   **Codex of Deliberation:** The formal protocol governing the decision-making processes of the human oversight committees.
*   **ESIRB (Ethical & Societal Impact Review Board):** An oversight body composed of external experts focused on the ethical and societal implications of the AGI research.
*   **Inviolable Constraint:** A fundamental rule that the AGI system is physically or logically prevented from violating.
*   **Post-Alignment Paradigm:** A framework that moves beyond the goal of instilling values in an AGI and instead focuses on external control, governance, and verifiable constraints.
*   **PTOC (Project Technical Oversight Committee):** An oversight body composed of technical experts responsible for the daily safety and operation of the AGI research project.
*   **Sentry System:** An independent monitoring system that observes the AGI's internal state and resource usage for anomalies.
*   **Value Grounding Problem (VGP):** The philosophical and practical challenge of how an AGI could learn or understand human values without already having a foundational understanding of what values are.
