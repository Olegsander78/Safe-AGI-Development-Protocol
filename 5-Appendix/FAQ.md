# Frequently Asked Questions

## General

**Q: What is the "Corralled Superintelligence" paradigm?**
A: It's a safety framework that prioritizes external control and governance of AGI through inviolable constraints and human oversight, instead of relying on the AGI internally learning and adopting human values.

**Q: Who is this framework for?**
A: Researchers, developers, policy makers, ethicists, and organizations involved or interested in the safe development of Artificial General Intelligence.

**Q: Is this a proven solution?**
A: No. This is a theoretical blueprint and a starting point for discussion, debate, and further development. It requires rigorous expert review and practical validation.

## Technical

**Q: What is an "Inviolable Constraint"?**
A: A rule that the AGI system *cannot* violate without an external, human-authorized change to the constraint logic itself. The goal is to make these constraints formally verified or hardware-enforced.

**Q: What is the difference between the Sentry and the Constraint Enforcer?**
A: The **Sentry** is a monitoring system that watches the AGI's state and raises alerts. The **Constraint Enforcer** is a gatekeeper that approves or denies the AGI's proposed actions based on a set of rules.

## Governance

**Q: How are the oversight committees (PTOC/ESIRB) formed?**
A: This blueprint defines their roles and responsibilities. The actual formation and selection processes for these committees are critical details that would need to be defined by any organization implementing this framework, ensuring diversity and independence.

**Q: What prevents the oversight committees from making mistakes?**
A: The Codex of Deliberation is designed to minimize error through structured processes (Devil's Advocate, Red Team/Blue Team, cooling-off periods) and checks-and-balances between the PTOC (technical) and ESIRB (ethical).
